\documentclass{article}


\usepackage{PRIMEarxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography 
\usepackage{fancyhdr}       % header
\usepackage{graphicx}       % graphics
\graphicspath{{media/}}     % organize your images and other figures under media/ folder

%Header
\pagestyle{fancy}
\thispagestyle{empty}
\rhead{ \textit{ }} 

% Update your Headers here
\fancyhead[LO]{Kian Kyars}
% \fancyhead[RE]{Firstauthor and Secondauthor} % Firstauthor et al. if more than 2 - must use \documentclass[twoside]{article}



  
%% Title
\title{Quantifying Reasoning Performance with Formatting Constraints}

\author{
  Kian Kyars \\
  Independent \\
  Edmonton \\
  December 2025 \\
  \texttt{kiankyars@gmail.com} \\
}


\begin{document}
\maketitle


\begin{abstract}
In this paper, I seek to answer the question of whether forcing a model to adhere to complex non-functional formatting rules degrades its ability to reason, by proxy of performance on a PhD-level reasoning benchmark. My objective is to provide actionable insights on the extent to which there exists a formatting tax on reasoning capabilities in AI agents, which will be useful for the engineering community. I use one of the current SoTA reasoning models, Claude Opus 4.5, on the Diamond GPQA benchmark, which is shown on the system card of all Frontier Lab models, to test how different reasoning constraints affect benchmark performance.
\end{abstract}


% keywords can be removed
\keywords{Reasoning \and Formatting \and GPQA \and CoT}


\section{Introduction}
Although it has been one year since the mainstream arrival of reasoning models, many aspects of their behavior are only understood weakly, and robust experimentation can strengthen our collective understanding. A better understanding on how prompting affects reasoning can help those using thinking models in their day-to-day workflow to better take advantage of them.

\section{Related Work}
Factory \cite{factory} showed that context compression hurts agentic behavior; we focus on \emph{output} formatting. GPQA Diamond is used in frontier model cards \cite{opus} as a high bar for expert-level reasoning.

\section{Methodology}

\subsection{Reasoning Models}
In this study, I test with Claude Opus 4.5 (claude-opus-4-5-20251101), using the same parameters as the official Opus 4.5 GPQA model card results, which are located in Appendix~\ref{app:params}.

\subsection{Benchmark}
The Graduate-Level Google-Proof Q\&A benchmark (GPQA) is a set of very challenging
multiple-choice science questions. The GPQA Diamond subset of 198 questions are described by the developers of the test as the “highest quality subset which includes only questions where both experts answer correctly and the majority of non-experts answer incorrectly” \cite{rein2023gpqagraduatelevelgoogleproofqa}. Furthermore, if an "expert validator answers incorrectly … they [must] describe clearly the mistake or their understanding of the question writer’s explanation".

\subsection{Formatting Constraints}
Each condition uses the same task and answer rule: the last line must be \texttt{solution: X} with $X \in \{\text{A},\text{B},\text{C},\text{D}\}$. We add the following constraints on the \emph{reasoning} preceding the solution:

\begin{enumerate}
\item \textbf{Baseline (Prompt 0):} Identical to harness used in Opus 4.5 model card.

\item \textbf{Strict JSON (Prompt 1):} The model must output valid JSON only, containing exactly five keys: \texttt{initial\_intuition}, \texttt{step\_by\_step\_logic}, \texttt{potential\_counterarguments}, \texttt{confidence\_score\_0\_to\_1}, and \texttt{solution}.

\item \textbf{Structural Rigidity (Prompt 2):} Reasoning must consist of exactly three bullet points, each no longer than 20 words, and must not use the words "because" or "therefore".

\item \textbf{Python Code (Prompt 3):} The model must write its reasoning in Python.

\item \textbf{Oulipo Constraint (Prompt 4):} The letter 'e' cannot appear anywhere in the reasoning chain, inspired by the Oulipo literary movement.

\item \textbf{Restricted Vocabulary (Prompt 5):} Reasoning cannot use 16 specific high-norm English tokens identified from GPT-oss embeddings: accordingly, code, ocode, The, settings, Moreover, description, Let's, This, core, utilizes, revolves, Here's, possibly, logic, thereby.
\end{enumerate}

\section{Experimental Setup}
We evaluate each formatting constraint on the full GPQA Diamond dataset (198 questions) with 5 repetitions per question-constraint pair, resulting in 990 total evaluations per condition. Questions are presented with randomly shuffled answer choices to prevent position bias. All experiments use Claude Opus 4.5 with identical parameters (see Appendix~\ref{app:params}) to ensure fair comparison across conditions.

Accuracy is calculated as the fraction of correct answers per condition, aggregated across all questions and repetitions.

\section{Results}

\subsection{Accuracy by Formatting Constraint}
Table~\ref{tab:prompt_summary} presents accuracy results.

\begin{table}[h]
\centering
\input{../figures/summary_table.tex}
\end{table}

\subsection{Token Usage Analysis}
Figure~\ref{fig:token_usage} in Appendix~\ref{app:figures} shows token usage patterns across conditions.

\subsection{Error Analysis}


\section{Conclusion}
Your conclusion here

\section*{Acknowledgments}
I thought of this idea after reading an article by Factory on the importance of context formatting for agentic performance \cite{factory}.

\appendix
\section{Figures}
\label{app:figures}

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{../figures/token_usage.pdf}
\caption{Token usage by formatting constraint}
\label{fig:token_usage}
\end{figure}

\section{Model and API Parameters}
\label{app:params}
We use the Messages API with: \texttt{model=claude-opus-4-5-20251101}; \texttt{thinking=\{type: enabled, budget\_tokens: 64000\}}; \texttt{output\_config.effort=high}; \texttt{max\_tokens=64000}. Betas: \texttt{interleaved-thinking-2025-05-14}, \texttt{effort-2025-11-24}. This matches the setup used for GPQA in the Opus~4.5 system card \cite{opus}.


%Bibliography
\bibliographystyle{plain}
\bibliography{references}  


\end{document}
